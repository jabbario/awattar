{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Pattern Recognition\n",
    "\n",
    "For this task, you will use the following 4 CSV files:\n",
    "\n",
    "1. **customers_consumptions.csv**  \n",
    "2. **customers_metadata.csv**  \n",
    "3. **weather_data.csv**  \n",
    "4. **price_data.csv**\n",
    "\n",
    "---\n",
    "\n",
    "## Input Data\n",
    "\n",
    "### **customers_consumptions.csv**  \n",
    "This file contains consumption data of a subset of our customers. Key columns include:  \n",
    "- **meteringpoint_id**: Unique customer identifier.  \n",
    "- **validfrom**: Timestamp marking the start of the 15-minute measurement interval.  \n",
    "- **quantity**: Electricity consumed (in kWh) during the 15-minute interval.  \n",
    "\n",
    "The data spans varying time intervals for different customers.\n",
    "\n",
    "---\n",
    "\n",
    "### **customers_metadata.csv**  \n",
    "This file maps customers to their nearest weather station:  \n",
    "- **meteringpoint_id**: Unique customer identifier.  \n",
    "- **weatherstation_id**: Closest weather station to the customer.\n",
    "\n",
    "---\n",
    "\n",
    "### **weather_data.csv**  \n",
    "Weather station measurements include:  \n",
    "- **validfrom**: Timestamp of the weather measurement.  \n",
    "- **air_temp**: Air temperature in degrees Celsius.  \n",
    "- **ghi**: Global horizontal irradiation (sum of solar energy per unit area).  \n",
    "- **cloud_opacity**: Cloud opacity percentage (0% = clear, 100% = opaque).  \n",
    "- **precipitable_water**: Water vapor amount in \\( kg/m^2 \\).\n",
    "\n",
    "---\n",
    "\n",
    "### **price_data.csv**  \n",
    "This file contains electricity market prices sampled hourly:  \n",
    "- **timestamp**: Start of the 1-hour interval.  \n",
    "- **price**: Electricity price for that hour (constant across Austria).\n",
    "\n",
    "---\n",
    "\n",
    "## Problem Description\n",
    "\n",
    "Your goal is to **cluster customers into two groups** based on their **consumption behavior**. While we have an idea of a useful grouping, you are encouraged to experiment and propose novel approaches. Consider the following:  \n",
    "- Patterns in consumption over time (e.g., daily or seasonal trends).  \n",
    "- Relationships between consumption and external factors, such as weather conditions and electricity prices.\n",
    "\n",
    "For example, a lot of our customers have electric vehicles which they charge when the prices are low. Others have home devices that can track electricity prices, and get activated when the price is low. These types of customers should exhibit highly price related behaviour.\n",
    "\n",
    "We welcome methods ranging from **simple correlation analysis** to **advanced machine learning techniques**.\n",
    "\n",
    "---\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "1. **Output**  \n",
    "   - Provide a file with customer groupings in the following format:  \n",
    "\n",
    "     | meteringpoint_id | cluster |  \n",
    "     |------------------|---------|  \n",
    "     | 12345           | 0       |  \n",
    "     | 67890           | 1       |  \n",
    "\n",
    "     Here, the **cluster** column is binary (0 or 1).\n",
    "\n",
    "2. **Methodology Description**  \n",
    "   - Describe your thought process, clustering approach, and assumptions. This can be in the form of:  \n",
    "     - Code comments.  \n",
    "     - A short report or markdown file.\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Notes\n",
    " \n",
    "- You are free to use libraries such as **pandas**, **scikit-learn**, or any other tools suitable for analysis.  \n",
    "- Creativity and interpretability are key—feel free to justify and visualize your results as you see fit.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Forecasting\n",
    "\n",
    "For this task, all of the data is provided within the **average_consumption.csv** file.\n",
    "\n",
    "---\n",
    "\n",
    "## Input Data\n",
    "\n",
    "The **average_consumption.csv** file contains the following columns:  \n",
    "- **validfrom**: Timestamp of the 15-minute measurement interval (valid for the next 15 minutes).  \n",
    "- **avg**: The target/dependent variable – average electricity consumption of a subset of customers (in kWh).  \n",
    "- **Other columns**: Various explanatory variables that can be used for forecasting, including:  \n",
    "   - Weather-related measurements (e.g., temperature, global horizontal irradiation, cloud opacity).  \n",
    "   - Electricity prices.  \n",
    "\n",
    "---\n",
    "\n",
    "## Problem Description\n",
    "\n",
    "Your goal is to develop a **working forecasting algorithm** to predict the **avg** column (average consumption). While we will test your solution on out-of-sample data, the focus is not on achieving perfect accuracy but rather on how you approach and handle the task.  \n",
    "\n",
    "You are encouraged to:  \n",
    "- Preprocess the data appropriately (e.g. scale features).  \n",
    "- Explore and engineer new features that may improve forecasting performance.  \n",
    "- Implement proper **cross-validation techniques** to validate your model.  \n",
    "- Use any forecasting techniques or algorithms you deem appropriate.\n",
    "- The metric we use in the forecasting pipeline is called **Area Percentage Error** and we define it as follows:\n",
    "\n",
    "$$ APE(y, \\hat{y}) = \\frac{\\sum_i |y_i - \\hat{y_i}|}{\\sum_i |y_i|}, $$\n",
    "where $y$ are true values, and $\\hat{y}$ are the predicted/forecasted values. We would like you to use this metric.\n",
    "\n",
    "---\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "1. **Code**  \n",
    "   - A working implementation of your forecasting algorithm.  \n",
    "   - Steps for data preprocessing, feature engineering, and model training.  \n",
    "   - Include clear comments to explain your methodology and logic.  \n",
    "\n",
    "2. **Model Output**  \n",
    "   - Your code should produce predictions for the **avg** column on a test dataset (or unseen data).\n",
    "   - We will use input data in the same format as the provided one - perhaps the best way is to package\n",
    "   the trained model into a function that takes in a dataframe and outputs the predictions.\n",
    "\n",
    "3. **Methodology Description**  \n",
    "   - Describe your thought process and approach to the problem.  \n",
    "   - Explain the techniques used for data preprocessing, feature engineering, model selection, and validation.  \n",
    "   - If possible, include a brief evaluation of your model (e.g., errors or performance metrics like RMSE, MAE).  \n",
    "\n",
    "---\n",
    "\n",
    "## Additional Notes\n",
    "\n",
    "- Focus on demonstrating your understanding of **forecasting techniques** rather than perfect accuracy.  \n",
    "- Use appropriate libraries such as **pandas**, **scikit-learn**, **statsmodels**, or **machine learning frameworks** like TensorFlow or PyTorch.  \n",
    "- Creativity, thoroughness, and clarity in your approach are key.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
