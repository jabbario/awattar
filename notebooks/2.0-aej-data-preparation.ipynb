{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "This notebooks joins data, aligns time granularity and does some initial feature engineering for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "DATA_DIR = os.path.join(cwd, '..', 'data')\n",
    "INT_DATA_DIR = os.path.join(cwd, '..', 'data', 'interim')\n",
    "RAW_DATA_DIR = os.path.join(cwd, '..', 'data', 'raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load all required CSV files\"\"\"\n",
    "    consumptions = pd.read_csv(os.path.join(RAW_DATA_DIR,'customers_consumptions.csv'))\n",
    "    metadata = pd.read_csv(os.path.join(RAW_DATA_DIR,'customers_metadata.csv'))\n",
    "    weather = pd.read_csv(os.path.join(RAW_DATA_DIR,'weather_data.csv'))\n",
    "    prices = pd.read_csv(os.path.join(RAW_DATA_DIR,'price_data.csv'))\n",
    "    \n",
    "    # Convert timestamp columns to datetime\n",
    "    consumptions['validfrom'] = pd.to_datetime(consumptions['validfrom'])\n",
    "    weather['validfrom'] = pd.to_datetime(weather['validfrom'])\n",
    "    prices['validfrom'] = pd.to_datetime(prices['validfrom'])\n",
    "    \n",
    "    # sort\n",
    "    consumptions = consumptions.sort_values(by=[\"meteringpoint_id\", \"validfrom\"])\n",
    "    weather = weather.sort_values(by=[\"weatherstation_id\", \"validfrom\"])\n",
    "    \n",
    "    return consumptions, metadata, weather, prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_and_ffill_prices(df, timestamp_col, freq='15T', value_cols=None):\n",
    "    \"\"\"\n",
    "    Resample a DataFrame to a specified frequency and forward fill values.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[timestamp_col] = pd.to_datetime(df[timestamp_col])\n",
    "    if value_cols is None:\n",
    "        value_cols = [col for col in df.columns if col != timestamp_col]\n",
    "    df = df.set_index(timestamp_col)\n",
    "    df_resampled = df[value_cols].resample(freq).ffill()\n",
    "    df_resampled = df_resampled.reset_index()\n",
    "    \n",
    "    return df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_weather_gaps(weather_df, freq='15T'):\n",
    "    \"\"\"\n",
    "    Fill gaps in weather data by resampling and forward filling.\n",
    "    \"\"\"\n",
    "    df = weather_df.copy()\n",
    "    \n",
    "    # Ensure timestamp is datetime\n",
    "    df['validfrom'] = pd.to_datetime(df['validfrom'])\n",
    "    value_cols = ['air_temp', 'ghi', 'cloud_opacity', 'precipitable_water']\n",
    "    \n",
    "    filled_dfs = []\n",
    "    for station_id in df['weatherstation_id'].unique():\n",
    "        station_data = df[df['weatherstation_id'] == station_id].copy()\n",
    "        station_data = station_data.set_index('validfrom')\n",
    "        filled_data = station_data[value_cols].resample(freq).ffill()\n",
    "        filled_data = filled_data.reset_index()\n",
    "        filled_data['weatherstation_id'] = station_id\n",
    "        \n",
    "        filled_dfs.append(filled_data)\n",
    "    \n",
    "    result = pd.concat(filled_dfs, ignore_index=True)\n",
    "    result = result.sort_values(['weatherstation_id', 'validfrom'])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(df, group_col='meteringpoint_id'):\n",
    "    \"\"\"\n",
    "    Normalize data using z-score within each group.\n",
    "    \"\"\"\n",
    "    normalized = df.copy()\n",
    "    \n",
    "    # Columns to normalize\n",
    "    cols_to_normalize = ['quantity', 'air_temp', 'ghi', 'cloud_opacity', \n",
    "                        'precipitable_water', 'price']\n",
    "    \n",
    "    # Normalize each feature within each group\n",
    "    for col in cols_to_normalize:\n",
    "        normalized[f'{col}_norm'] = (df.groupby(group_col)[col]\n",
    "                                   .transform(lambda x: (x - x.mean()) / x.std()))\n",
    "    \n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumptions_df, metadata_df, weather_df, prices_df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = fill_weather_gaps(weather_df, freq='15T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df = resample_and_ffill_prices(\n",
    "    df=prices_df,\n",
    "    timestamp_col='validfrom',\n",
    "    freq='15T',\n",
    "    value_cols=['price']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = (consumptions_df\n",
    " .merge(metadata_df, on=[\"meteringpoint_id\"], how='left')\n",
    " .merge(weather_df, on=[\"weatherstation_id\", \"validfrom\"], how='left')\n",
    " .merge(prices_df, on=[\"validfrom\"], how=\"left\")\n",
    " .sort_values(by=[\"meteringpoint_id\", \"validfrom\"])\n",
    " .drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_df = normalise(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(os.path.join(INT_DATA_DIR, 'merged.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_df.to_csv(os.path.join(INT_DATA_DIR, 'norm_merged.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
