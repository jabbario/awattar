{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "This notebooks joins data, aligns time granularity and does some initial feature engineering for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "DATA_DIR = os.path.join(cwd, '..', 'data')\n",
    "INT_DATA_DIR = os.path.join(cwd, '..', 'data', 'interim')\n",
    "RAW_DATA_DIR = os.path.join(cwd, '..', 'data', 'raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load all required CSV files\"\"\"\n",
    "    consumptions = pd.read_csv(os.path.join(RAW_DATA_DIR,'customers_consumptions.csv'))\n",
    "    metadata = pd.read_csv(os.path.join(RAW_DATA_DIR,'customers_metadata.csv'))\n",
    "    weather = pd.read_csv(os.path.join(RAW_DATA_DIR,'weather_data.csv'))\n",
    "    prices = pd.read_csv(os.path.join(RAW_DATA_DIR,'price_data.csv'))\n",
    "    \n",
    "    # Convert timestamp columns to datetime\n",
    "    consumptions['validfrom'] = pd.to_datetime(consumptions['validfrom'])\n",
    "    weather['validfrom'] = pd.to_datetime(weather['validfrom'])\n",
    "    prices['validfrom'] = pd.to_datetime(prices['validfrom'])\n",
    "    \n",
    "    # sort\n",
    "    consumptions = consumptions.sort_values(by=[\"meteringpoint_id\", \"validfrom\"])\n",
    "    weather = weather.sort_values(by=[\"weatherstation_id\", \"validfrom\"])\n",
    "    \n",
    "    return consumptions, metadata, weather, prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_and_ffill_prices(df, timestamp_col, freq='15T', value_cols=None):\n",
    "    \"\"\"\n",
    "    Resample a DataFrame to a specified frequency and forward fill values.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[timestamp_col] = pd.to_datetime(df[timestamp_col])\n",
    "    if value_cols is None:\n",
    "        value_cols = [col for col in df.columns if col != timestamp_col]\n",
    "    df = df.set_index(timestamp_col)\n",
    "    df_resampled = df[value_cols].resample(freq).ffill()\n",
    "    df_resampled = df_resampled.reset_index()\n",
    "    \n",
    "    return df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_weather_gaps(weather_df, freq='15T'):\n",
    "    \"\"\"\n",
    "    Fill gaps in weather data by resampling and forward filling.\n",
    "    \"\"\"\n",
    "    df = weather_df.copy()\n",
    "    \n",
    "    # Ensure timestamp is datetime\n",
    "    df['validfrom'] = pd.to_datetime(df['validfrom'])\n",
    "    value_cols = ['air_temp', 'ghi', 'cloud_opacity', 'precipitable_water']\n",
    "    \n",
    "    filled_dfs = []\n",
    "    for station_id in df['weatherstation_id'].unique():\n",
    "        station_data = df[df['weatherstation_id'] == station_id].copy()\n",
    "        station_data = station_data.set_index('validfrom')\n",
    "        filled_data = station_data[value_cols].resample(freq).ffill()\n",
    "        filled_data = filled_data.reset_index()\n",
    "        filled_data['weatherstation_id'] = station_id\n",
    "        \n",
    "        filled_dfs.append(filled_data)\n",
    "    \n",
    "    result = pd.concat(filled_dfs, ignore_index=True)\n",
    "    result = result.sort_values(['weatherstation_id', 'validfrom'])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_consumption(df, freq='1H'):\n",
    "    \"\"\"\n",
    "    Resample consumption data to a specified frequency and aggregate values.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure timestamp is datetime\n",
    "    df['validfrom'] = pd.to_datetime(df['validfrom'])\n",
    "    \n",
    "    filled_dfs = []\n",
    "    \n",
    "    # Process each meter separately\n",
    "    for meter_id in df['meteringpoint_id'].unique():\n",
    "        meter_data = df[df['meteringpoint_id'] == meter_id].copy()\n",
    "        meter_data = meter_data.set_index('validfrom')\n",
    "        filled_data = meter_data[['quantity']].resample(freq).mean()\n",
    "        filled_data = filled_data.reset_index()\n",
    "        filled_data['meteringpoint_id'] = meter_id\n",
    "        \n",
    "        filled_dfs.append(filled_data)\n",
    "    \n",
    "    result = pd.concat(filled_dfs, ignore_index=True)\n",
    "    result = result.sort_values(['meteringpoint_id', 'validfrom'])\n",
    "    \n",
    "    print(f\"Original shape: {df.shape}\")\n",
    "    print(f\"Resampled shape: {result.shape}\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(df, group_col='meteringpoint_id'):\n",
    "    \"\"\"\n",
    "    Normalize data using z-score within each group.\n",
    "    \"\"\"\n",
    "    normalized = df.copy()\n",
    "    \n",
    "    # Columns to normalize\n",
    "    cols_to_normalize = ['quantity', 'air_temp', 'ghi', 'cloud_opacity', \n",
    "                        'precipitable_water', 'price']\n",
    "    \n",
    "    # Normalize each feature within each group\n",
    "    for col in cols_to_normalize:\n",
    "        normalized[f'{col}_norm'] = (df.groupby(group_col)[col]\n",
    "                                   .transform(lambda x: (x - x.mean()) / x.std()))\n",
    "    \n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumptions_df, metadata_df, weather_df, prices_df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = fill_weather_gaps(weather_df, freq='15T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df = resample_and_ffill_prices(\n",
    "    df=prices_df,\n",
    "    timestamp_col='validfrom',\n",
    "    freq='15T',\n",
    "    value_cols=['price']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = (consumptions_df\n",
    " .merge(metadata_df, on=[\"meteringpoint_id\"], how='left')\n",
    " .merge(weather_df, on=[\"weatherstation_id\", \"validfrom\"], how='left')\n",
    " .merge(prices_df, on=[\"validfrom\"], how=\"left\")\n",
    " .sort_values(by=[\"meteringpoint_id\", \"validfrom\"])\n",
    " .drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_df = normalise(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meteringpoint_id</th>\n",
       "      <th>validfrom</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>261b7930-dd7e-43f0-8a42-4f31d97f9edb</td>\n",
       "      <td>2024-01-01 00:00:00+00:00</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>261b7930-dd7e-43f0-8a42-4f31d97f9edb</td>\n",
       "      <td>2024-01-01 00:15:00+00:00</td>\n",
       "      <td>0.306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>261b7930-dd7e-43f0-8a42-4f31d97f9edb</td>\n",
       "      <td>2024-01-01 00:30:00+00:00</td>\n",
       "      <td>0.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>261b7930-dd7e-43f0-8a42-4f31d97f9edb</td>\n",
       "      <td>2024-01-01 00:45:00+00:00</td>\n",
       "      <td>0.184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>261b7930-dd7e-43f0-8a42-4f31d97f9edb</td>\n",
       "      <td>2024-01-01 01:00:00+00:00</td>\n",
       "      <td>0.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444067</th>\n",
       "      <td>eba9a77e-589f-4c63-b7d2-8506c0cb8a59</td>\n",
       "      <td>2024-10-31 22:45:00+00:00</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444089</th>\n",
       "      <td>eba9a77e-589f-4c63-b7d2-8506c0cb8a59</td>\n",
       "      <td>2024-10-31 23:00:00+00:00</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444108</th>\n",
       "      <td>eba9a77e-589f-4c63-b7d2-8506c0cb8a59</td>\n",
       "      <td>2024-10-31 23:15:00+00:00</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444134</th>\n",
       "      <td>eba9a77e-589f-4c63-b7d2-8506c0cb8a59</td>\n",
       "      <td>2024-10-31 23:30:00+00:00</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444153</th>\n",
       "      <td>eba9a77e-589f-4c63-b7d2-8506c0cb8a59</td>\n",
       "      <td>2024-10-31 23:45:00+00:00</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>444160 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            meteringpoint_id                 validfrom  \\\n",
       "4       261b7930-dd7e-43f0-8a42-4f31d97f9edb 2024-01-01 00:00:00+00:00   \n",
       "14      261b7930-dd7e-43f0-8a42-4f31d97f9edb 2024-01-01 00:15:00+00:00   \n",
       "22      261b7930-dd7e-43f0-8a42-4f31d97f9edb 2024-01-01 00:30:00+00:00   \n",
       "28      261b7930-dd7e-43f0-8a42-4f31d97f9edb 2024-01-01 00:45:00+00:00   \n",
       "36      261b7930-dd7e-43f0-8a42-4f31d97f9edb 2024-01-01 01:00:00+00:00   \n",
       "...                                      ...                       ...   \n",
       "444067  eba9a77e-589f-4c63-b7d2-8506c0cb8a59 2024-10-31 22:45:00+00:00   \n",
       "444089  eba9a77e-589f-4c63-b7d2-8506c0cb8a59 2024-10-31 23:00:00+00:00   \n",
       "444108  eba9a77e-589f-4c63-b7d2-8506c0cb8a59 2024-10-31 23:15:00+00:00   \n",
       "444134  eba9a77e-589f-4c63-b7d2-8506c0cb8a59 2024-10-31 23:30:00+00:00   \n",
       "444153  eba9a77e-589f-4c63-b7d2-8506c0cb8a59 2024-10-31 23:45:00+00:00   \n",
       "\n",
       "        quantity  \n",
       "4          0.156  \n",
       "14         0.306  \n",
       "22         0.211  \n",
       "28         0.184  \n",
       "36         0.523  \n",
       "...          ...  \n",
       "444067     0.002  \n",
       "444089     0.001  \n",
       "444108     0.002  \n",
       "444134     0.001  \n",
       "444153     0.001  \n",
       "\n",
       "[444160 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumptions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(os.path.join(INT_DATA_DIR, 'merged.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_df.to_csv(os.path.join(INT_DATA_DIR, 'norm_merged.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
